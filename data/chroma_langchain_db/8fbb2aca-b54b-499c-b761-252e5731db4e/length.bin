invalid type: string "Q(Q), K=F F NK(K) (3) whereFF NQ andFF NK is proposed Q-Adapter and K-Adapter, respectively, QR ndk , K Rcdk ,dis the dimension of the model, andd k is the dimension of head.d k d. Attention DistillationWe propose an attention distillation strategy to train the Q-Adapter and K- Adapter. Where, we treatA s as student attention, and a type of aggregation of original attentionA 